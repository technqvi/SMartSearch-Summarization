{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68a8818-c724-433e-b6f5-2d2f1c0dc62c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_date_query='2023-12-22'\n",
    "end_date_query=None\n",
    "# end_date_query='2023-12-24' \n",
    "\n",
    "# def create_incident_json_data(start_date_query:str,end_date_query:str,config)-> list[str] :\n",
    "# \"\"\"\n",
    "# Retrive incident data from Database to create json file and save them in local directory.\n",
    "# Args:\n",
    "#     start_date_query (str): Start date to get data.\n",
    "#     end_date_query (str): End date to get data.\n",
    "#     config : .env Config file\n",
    "# Returns:\n",
    "#     list[str]: list of newly created json files to be imported to google cloud storage.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c39b3f6-bba0-4a86-a7e9-06936925e4e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from google.cloud import bigquery\n",
    "from dotenv import dotenv_values\n",
    "import re\n",
    "\n",
    "from google.cloud.exceptions import NotFound\n",
    "from google.api_core.exceptions import BadRequest\n",
    "\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006faf12-708d-41d8-a92e-e675cd0fd1a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env_path='.env'\n",
    "config = dotenv_values(dotenv_path=env_path)\n",
    "\n",
    "local_data_path=config['INPUT_SEARCH_DATA_PATH']\n",
    "url_search_detail=config['SEARCH_DETAIL_URL']\n",
    "customDocumentId=config['CUSTOM_DOCUMENT_ID']\n",
    "\n",
    "str_postfix=\"daily_incident\"\n",
    "\n",
    "listNewlyCratedFiles=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c550a3-31d9-4ab2-96b5-86788b3ed1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt_imported=datetime.now()\n",
    "str_imported=dt_imported.strftime('%Y-%m-%d %H:%M:%S')\n",
    "str_date_imported=dt_imported.strftime('%d%m%Y_%H%M')\n",
    "print(f\"Imported DateTime: {str_imported}\" )\n",
    "print(f\"Imported Date: {str_date_imported}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02058f8d-cc89-4eea-8fd4-1c7995a0a6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_postgres_conn():\n",
    " try:\n",
    "  conn = psycopg2.connect(\n",
    "        database=config['DATABASES_NAME'], user=config['DATABASES_USER'],\n",
    "      password=config['DATABASES_PASSWORD'], host=config['DATABASES_HOST']\n",
    "     )\n",
    "  return conn\n",
    "\n",
    " except Exception as error:\n",
    "  print(error)      \n",
    "  raise error\n",
    "def list_data(sql,params,connection):\n",
    " df=None   \n",
    " with connection.cursor() as cursor:\n",
    "    \n",
    "    if params is None:\n",
    "       cursor.execute(sql)\n",
    "    else:\n",
    "       cursor.execute(sql,params)\n",
    "    \n",
    "    columns = [col[0] for col in cursor.description]\n",
    "    dataList = [dict(zip(columns, row)) for row in cursor.fetchall()]\n",
    "    df = pd.DataFrame(data=dataList) \n",
    " return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b15bef7-37e5-4922-8c07-62b52691e37b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if end_date_query  is None:\n",
    "    date_filter=f\"incident.updated_at>='{start_date_query}'\"\n",
    "else:\n",
    "    date_filter=f\"incident.updated_at>='{start_date_query}' and incident.updated_at<'{end_date_query}'\"\n",
    "\n",
    "# ,CONCAT(incident_no,' - Serial: ',serial_number,' - Model:',model.model_name,' - Brand:',brand_name) as title\n",
    "sql_incident=f\"\"\"\n",
    "\n",
    "select\n",
    "incident.id as _id ,incident.incident_no as incident_no,ac.company_name\n",
    ",CONCAT('{url_search_detail}',incident.id,'/') as uri,\n",
    "\n",
    "incident.incident_subject as title, incident_description description\n",
    "\n",
    ",xtype.incident_type_name as incident_type,severity.severity_name as  severity\n",
    "\n",
    ",CONCAT(brand.brand_name,' - ',model.model_name,'- ',serial_number) as inventory_item\n",
    ",brand.brand_name as brand,model.model_name as model,inventory.serial_number\n",
    "\n",
    "\n",
    "from app_incident as incident\n",
    "inner join app_incident_type as  xtype on incident.incident_type_id = xtype.id\n",
    "inner join  app_incident_severity as severity on  incident.incident_severity_id = severity.id\n",
    "inner join app_inventory as inventory on incident.inventory_id = inventory.id\n",
    "inner join app_brand as brand on inventory.brand_id = brand.id\n",
    "inner join app_model as model on inventory.model_id = model.id\n",
    "inner join app_project ap on inventory.project_id = ap.id\n",
    "inner join app_company ac on ap.company_id = ac.id\n",
    "\n",
    "where {date_filter}\n",
    "and inventory.is_dummy=False and incident.incident_status_id<>3\n",
    "\n",
    "order by incident.id \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(sql_incident)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac67eab-20f6-4676-886b-d8184d4150ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_detail=\"\"\"\n",
    "select  detail.id as detail_id, detail.incident_master_id as incident_id ,\n",
    "workaround_resolution as solution\n",
    ",(select service_team_name from app_serviceteam as team where team.id= service_team_id ) as engineer_team\n",
    "from app_incident_detail detail\n",
    " where detail.incident_master_id =  %(incident_id_param)s \n",
    " \"\"\"\n",
    "print(sql_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac777d07-3149-4d68-bad7-037204f26140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ILLEGAL_CHARACTERS_RE = re.compile(r\"[\\000-\\010]|[\\013-\\014]|[\\016-\\037]\")\n",
    "# \\r\\n\\r  \\r\\n\n",
    "# https://www.geeksforgeeks.org/python-removing-newline-character-from-string/\n",
    "def replace_ILLEGAL_CHARACTERS(text):\n",
    "   text_fixed = _ILLEGAL_CHARACTERS_RE.sub(\"\", text)\n",
    "   return  text_fixed  \n",
    "\n",
    "def replace_NewLine_CHARACTERS(text):\n",
    "   text_fixed= text.replace(\"\\r\\n\", \" \").replace(\"\\r\\n\\r\", \" \")   \n",
    "   return  text_fixed  \n",
    "\n",
    "df_all=list_data(sql_incident,None,get_postgres_conn())\n",
    "print(f\"List all issues dataframe : {len(df_all)}\")\n",
    "if df_all.empty==True:\n",
    "    print(\"No data to create Json files\")\n",
    "    # return listNewlyCratedFiles\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ed54bd-70c8-462b-b448-5e6c5fc83772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all[customDocumentId]=df_all[customDocumentId].astype(str)\n",
    "\n",
    "\n",
    "df_all['description']=df_all['description'].apply(replace_ILLEGAL_CHARACTERS) \n",
    "df_all['description']=df_all['description'].apply(replace_NewLine_CHARACTERS)\n",
    "\n",
    "print(df_all.info())\n",
    "df_all.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e0b91b-bd73-4b08-8532-9c098f6b885e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write json file/dataframe\n",
    "file_name=f\"{str_date_imported}-{str_postfix}.ndjson\"\n",
    "with open(f'{local_data_path}\\\\{file_name}', 'w',encoding='utf8') as f:\n",
    "    \n",
    "    for index, srCaseItem in df_all.iterrows(): \n",
    "        id=int(srCaseItem[customDocumentId])\n",
    "        srDict=srCaseItem.to_dict()\n",
    "\n",
    "        print(f\"============================{id}==============================\")    \n",
    "        #incident_update_at= incident['imported_at']\n",
    "        df_detail = list_data(sql_detail,{\"incident_id_param\": id},get_postgres_conn())\n",
    "        if df_detail.empty==False:\n",
    "\n",
    "          df_detail=df_detail.drop(columns=['incident_id','detail_id'])  \n",
    "          df_detail['solution']=df_detail['solution'].apply(replace_ILLEGAL_CHARACTERS)\n",
    "          df_detail['solution']=df_detail['solution'].apply(replace_NewLine_CHARACTERS)  \n",
    "            \n",
    "          detailDict = df_detail.to_dict(orient = 'records')\n",
    "          srDict['solution_list']=detailDict\n",
    "\n",
    "        json_object = json.dumps(srDict,ensure_ascii=False)\n",
    "        f.write(json_object + '\\n')\n",
    "            \n",
    "listNewlyCratedFiles.append(file_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b870f50-9bc2-4eb0-8294-41660bf18fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# return  listNewlyCratedFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2411e1e2-78e9-45f5-9190-d640ca35bac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da936c-a69f-4869-8ee7-50123309ceb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
